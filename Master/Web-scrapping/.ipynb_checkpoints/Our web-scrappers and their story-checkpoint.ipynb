{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our web-scrappers and their story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    \n",
    "1. [Introduction](#0)<br>\n",
    "2. [London Metal Exchange web-scrapping](#1)<br>\n",
    "3. [Premier Plant Hire (construction tools) web-scrapping](#2)<br>\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction<a id=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this challenge, two sets of data were required to be scrapped, namely: commodity prices (copper, steel) for the machine learning algorithm, and construction tools and their hire price for Power BI.\n",
    "\n",
    "**Commodity prices**\n",
    "\n",
    "The machine learning algorithm required daily commodity prices, with one file per commodity in a .csv format. These were scrapped from the London Metal Exchange's website, www.lme.com with a detailed explanation of the code below.\n",
    "\n",
    "Target: one csv file per commodity containing the date and price.\n",
    "\n",
    "**Construction tools for hire**\n",
    "\n",
    "The tools data was scrapped from the Premier Plant Hire, www.premierplanthire.co.uk. The website's structure has all construction tools separated by category, such as: dumpers, conveyor belts, power generation and so on.\n",
    "\n",
    "Within each category's page, the individual tools can be found in separate tables as shown in the below image with the number of tables varying per page.\n",
    "\n",
    "Target: a list of URLs for each tools category which can then be fed to Power BI to extract this data.\n",
    "\n",
    "![alt text](https://projsuccess.sharepoint.com/sites/PDACommunity/Shared%20Documents/Challenge%205b/Web-scrapping/tools1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## London Metal Exchange web-scrapping<a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code takes the LME's url, finds the 'Featured LME Prices' table on the homepage, scrappes the data and returns 3 individual .csv files for each target commodity as illustrated in the below image.\n",
    "\n",
    "The final csvs will only contain the date and price of the commodity as required by the machine learning algorithm.\n",
    "\n",
    "![alt text](https://projsuccess.sharepoint.com/sites/PDACommunity/Shared%20Documents/Challenge%205b/Web-scrapping/lme%20flow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Material</th>\n",
       "      <th>US$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LME Aluminium</td>\n",
       "      <td>2188.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LME Copper</td>\n",
       "      <td>9036.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LME Zinc</td>\n",
       "      <td>2787.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LME Nickel</td>\n",
       "      <td>16121.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LME Lead</td>\n",
       "      <td>1917.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LME Tin</td>\n",
       "      <td>27750.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LME Aluminium Alloy</td>\n",
       "      <td>2204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LME NASAAC</td>\n",
       "      <td>2271.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LME Cobalt</td>\n",
       "      <td>52750.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LME Gold*</td>\n",
       "      <td>1743.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LME Silver*</td>\n",
       "      <td>26.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LME Steel Scrap**</td>\n",
       "      <td>458.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LME Steel Rebar**</td>\n",
       "      <td>623.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Material       US$\n",
       "0         LME Aluminium   2188.00\n",
       "1            LME Copper   9036.00\n",
       "2              LME Zinc   2787.50\n",
       "3            LME Nickel  16121.00\n",
       "4              LME Lead   1917.50\n",
       "5               LME Tin  27750.00\n",
       "6   LME Aluminium Alloy   2204.00\n",
       "7            LME NASAAC   2271.00\n",
       "8            LME Cobalt  52750.00\n",
       "9             LME Gold*   1743.20\n",
       "10          LME Silver*     26.19\n",
       "11    LME Steel Scrap**    458.00\n",
       "12    LME Steel Rebar**    623.00"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing ALL required libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# reading the URL\n",
    "url = \"https://www.lme.com/\"\n",
    "header = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "  \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "r = requests.get(url, headers=header)\n",
    "\n",
    "# creating pandas dataframe to store scrapped data\n",
    "df = pd.read_html(r.text)\n",
    "df = df[0].rename(columns={df[0].columns[0]: \"Material\", df[0].columns[1]: \"US$\"})\n",
    "\n",
    "# extracting the date to be added as an additional dataframe column\n",
    "date = df[0].columns[0].split(': ')[1]\n",
    "\n",
    "# sanity check\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Material</th>\n",
       "      <th>US$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19 March 2021</td>\n",
       "      <td>LME Aluminium</td>\n",
       "      <td>2188.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19 March 2021</td>\n",
       "      <td>LME Copper</td>\n",
       "      <td>9036.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19 March 2021</td>\n",
       "      <td>LME Zinc</td>\n",
       "      <td>2787.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19 March 2021</td>\n",
       "      <td>LME Nickel</td>\n",
       "      <td>16121.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19 March 2021</td>\n",
       "      <td>LME Lead</td>\n",
       "      <td>1917.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19 March 2021</td>\n",
       "      <td>LME Tin</td>\n",
       "      <td>27750.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19 March 2021</td>\n",
       "      <td>LME Aluminium Alloy</td>\n",
       "      <td>2204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19 March 2021</td>\n",
       "      <td>LME NASAAC</td>\n",
       "      <td>2271.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19 March 2021</td>\n",
       "      <td>LME Cobalt</td>\n",
       "      <td>52750.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19 March 2021</td>\n",
       "      <td>LME Gold*</td>\n",
       "      <td>1743.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19 March 2021</td>\n",
       "      <td>LME Silver*</td>\n",
       "      <td>26.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19 March 2021</td>\n",
       "      <td>LME Steel Scrap**</td>\n",
       "      <td>458.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19 March 2021</td>\n",
       "      <td>LME Steel Rebar**</td>\n",
       "      <td>623.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date             Material       US$\n",
       "0   19 March 2021        LME Aluminium   2188.00\n",
       "1   19 March 2021           LME Copper   9036.00\n",
       "2   19 March 2021             LME Zinc   2787.50\n",
       "3   19 March 2021           LME Nickel  16121.00\n",
       "4   19 March 2021             LME Lead   1917.50\n",
       "5   19 March 2021              LME Tin  27750.00\n",
       "6   19 March 2021  LME Aluminium Alloy   2204.00\n",
       "7   19 March 2021           LME NASAAC   2271.00\n",
       "8   19 March 2021           LME Cobalt  52750.00\n",
       "9   19 March 2021            LME Gold*   1743.20\n",
       "10  19 March 2021          LME Silver*     26.19\n",
       "11  19 March 2021    LME Steel Scrap**    458.00\n",
       "12  19 March 2021    LME Steel Rebar**    623.00"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding date column into the dataframe\n",
    "df['Date']=date\n",
    "\n",
    "# moving date column to the front\n",
    "df=df[['Date'] + [col for col in df.columns if col !='Date']]\n",
    "\n",
    "# sanity check\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following three code cells extract each required commodity from the main dataframe, namely: copper, steel scrap and steel rebar, and follow the same structure.\n",
    "\n",
    "As can be noted from the code comments, there are an \"initial run\" and \"going forward\" codes. The \"initial run\" only needs to be run a single time as it creates the main .csv file in which the data is to be stored. Once run this line of code MUST be 'commented' to prevent it from overidding the existing file. The \"going forward\" code will simply append the existing files with the new date and price on a daily basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ungur\\anaconda30\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9036.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      US$\n",
       "1  9036.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting Copper dataframe\n",
    "copper=df[df['Material'] == 'LME Copper']\n",
    "\n",
    "# dropping Materials column as no longer required for the machine learning algorithm\n",
    "copper.drop(['Material'], axis=1, inplace=True)\n",
    "\n",
    "# initial run\n",
    "copper.to_csv('Copper.csv', index=False) # <-------------- COMMENT ONCE RUN\n",
    "\n",
    "# going forward\n",
    "#copper.to_csv('Copper.csv', mode='a', header=False, index=False) # <----------- UNCOMMENT ONCE INITIAL RUN COMPLETE\n",
    "\n",
    "# sanity check\n",
    "copper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ungur\\anaconda30\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>458.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      US$\n",
       "11  458.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting Steel Scrap dataframe\n",
    "steel_scrap=df[df['Material'] == 'LME Steel Scrap**']\n",
    "\n",
    "# dropping Materials column as no longer required for the machine learning algorithm\n",
    "steel_scrap.drop(['Material'], axis=1, inplace=True)\n",
    "\n",
    "# initial run\n",
    "steel_scrap.to_csv('Steel Scrap.csv', index=False) # <-------------- COMMENT ONCE RUN\n",
    "\n",
    "# going forward\n",
    "#steel_scrap.to_csv('Steel Scrap.csv', mode='a', header=False, index=False) # <----------- UNCOMMENT ONCE INITIAL RUN COMPLETE\n",
    "\n",
    "# sanity check\n",
    "steel_scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ungur\\anaconda30\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>623.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      US$\n",
       "12  623.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting Steel Rebar dataframe\n",
    "steel_rebar=df[df['Material'] == 'LME Steel Rebar**']\n",
    "\n",
    "# dropping Materials column as no longer required for the machine learning algorithm\n",
    "steel_rebar.drop(['Material'], axis=1, inplace=True)\n",
    "\n",
    "# initial run\n",
    "steel_rebar.to_csv('Steel Rebar.csv', index=False) # <-------------- COMMENT ONCE RUN\n",
    "\n",
    "# going forward\n",
    "#steel_rebar.to_csv('Steel Rebar.csv', mode='a', header=False, index=False) # <----------- UNCOMMENT ONCE INITIAL RUN COMPLETE\n",
    "\n",
    "# sanity check\n",
    "steel_rebar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files are now ready for the machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premier Plant Hire (construction tools) web-scrapping<a id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to generate a list of all categories' URLs, we took the sidebar from the \"For Hire\" section of the website: www.premierplanthire.co.uk/for-hire.\n",
    "\n",
    "The scrapper searches for the \"ul\" tag containing the \"sub-menu\" class and then returns a list of all URLs contained in the \"a\" tags. The reason we have assigned the \"sub-menu\" class is due to the sidebar headers (\"Diggers & Dumper\", \"Construction Tools\", etc) also having their own URL which wouldn't return the data required. This is shown in the below image's HTML code highlighted in red.\n",
    "\n",
    "![alt text](https://projsuccess.sharepoint.com/sites/PDACommunity/Shared%20Documents/Challenge%205b/Web-scrapping/toolsf.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.premierplanthire.co.uk/welding-tools-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/fixing-equipment',\n",
       " 'https://www.premierplanthire.co.uk/trenching-shoring-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/power-generators-for-hire/mobile-lighting-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/cutting-grinding-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/landscaping-gardening-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/surface-preparation-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/pumping-draining-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/general-building-roadworks-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/power-generators-for-hire/hybrid-generators-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/heating-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/red-diesel-gas-oil-for-sale',\n",
       " 'https://www.premierplanthire.co.uk/diamond-drilling-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/air-tools-compressors-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/trench-sheets',\n",
       " 'https://www.premierplanthire.co.uk/wood-saws-woodworking-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/painting-decorating-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/dumpers-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/mini-diggers-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/hydraulic-breaker-attachments-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/concrete-compaction-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/lighting-site-electrics',\n",
       " 'https://www.premierplanthire.co.uk/access-equipment-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/power-generators-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/breaking-drilling-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/the-particulator-2/the-particulator',\n",
       " 'https://www.premierplanthire.co.uk/conveyor-belts-for-hire',\n",
       " 'https://www.premierplanthire.co.uk/cleaning-for-hire']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing required libraries\n",
    "import urllib.request\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# reading url\n",
    "req= Request('https://www.premierplanthire.co.uk/for-hire',headers={'User-Agent': 'Mozilla/5.0'})\n",
    "page=urlopen(req).read()\n",
    "\n",
    "# creating soup\n",
    "soup=BeautifulSoup(page,'html.parser')\n",
    "#print(soup.prettify())\n",
    " \n",
    "# extracting data for the sub-menu entries - avoids pulling URL for sidebar headers\n",
    "sub_menus=soup.findAll('ul', {\"class\":'sub-menu'})\n",
    "sub_menus\n",
    "\n",
    "\n",
    "# looping through a tags to extract hrefs\n",
    "## note: soup.find pulls the 'ul' tags with the class 'sub-menu' into a list\n",
    "## each sub-menu in the sidebar is pulled as a single entry in the list\n",
    "## looping through each index of the list required to pull all hrefs\n",
    "i = 0\n",
    "plant_urls = []\n",
    "\n",
    "while i < len(sub_menus):\n",
    "    sub_pos = sub_menus[i]\n",
    "    for link in sub_pos.findAll('a'):\n",
    "        urls=link.get(\"href\")\n",
    "        plant_urls.append(urls)\n",
    "        #print(urls)   \n",
    "    i += 1\n",
    "\n",
    "# removing url duplicates    \n",
    "plant_urls_final = set(plant_urls)\n",
    "\n",
    "# turning set to list\n",
    "plant_urls_final = list(plant_urls_final)\n",
    "\n",
    "plant_urls_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list can then be fed to Power BI for further processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
